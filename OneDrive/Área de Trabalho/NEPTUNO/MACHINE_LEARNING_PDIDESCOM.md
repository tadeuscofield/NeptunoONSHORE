# ü§ñ MACHINE LEARNING NO NEPTUNO

**Como integrar IA/ML para potencializar o sistema**

---

## üéØ VIS√ÉO GERAL

### **Estado Atual:**
‚úÖ Sistema usa **benchmarks est√°ticos** (m√©dias da ind√∫stria)
‚úÖ C√°lculos **param√©tricos** (f√≥rmulas fixas)
‚úÖ **Exporta√ß√£o de dados** para ML (j√° implementado!)

### **Com Machine Learning:**
üöÄ **Previs√µes din√¢micas** baseadas em projetos reais
üöÄ **Aprendizado cont√≠nuo** (quanto mais PDIs, mais preciso)
üöÄ **Sugest√µes inteligentes** (alternativas t√©cnicas, riscos)
üöÄ **Detec√ß√£o de anomalias** (custos fora do padr√£o)

---

## üìä CASOS DE USO - ML NO NEPTUNO

### **1. PREVIS√ÉO DE CUSTOS INTELIGENTE** üî¥ PRIORIDADE ALTA

**Problema Atual:**
Sistema usa f√≥rmulas fixas:
```javascript
custo = profundidade √ó fator_lamina √ó fator_bacia
```

**Com ML:**
```
Modelo treinado com 100+ PDIs reais aprende padr√µes:
- Custos reais vs estimados
- Vari√°veis ocultas (clima, log√≠stica, fornecedores)
- Correla√ß√µes n√£o √≥bvias

Resultado: Precis√£o de ¬±5% (vs ¬±20% atual)
```

**Implementa√ß√£o:**

```python
# 1. Coletar dados (j√° exporta JSON!)
import pandas as pd
import json

# Carregar datasets de PDIs anteriores
pdis = []
for file in glob('exports/*.json'):
    with open(file) as f:
        pdis.append(json.load(f))

df = pd.DataFrame(pdis)

# 2. Treinar modelo
from sklearn.ensemble import RandomForestRegressor

features = ['num_pocos', 'profundidade_media', 'lamina_agua',
            'distancia_costa', 'tipo_instalacao_encoded']
target = 'custo_total_usd'

X = df[features]
y = df[target]

model = RandomForestRegressor(n_estimators=100)
model.fit(X, y)

# 3. Prever novo PDI
novo_pdi = {
    'num_pocos': 8,
    'profundidade_media': 3500,
    'lamina_agua': 2100,
    'distancia_costa': 185,
    'tipo_instalacao_encoded': 2  # FPSO
}

custo_previsto = model.predict([list(novo_pdi.values())])
# Resultado: USD 178.5M (¬±5%)
```

**Benef√≠cio:**
- Propostas comerciais mais precisas
- Menos retrabalho (ajustes de custo)
- Confian√ßa do cliente aumenta

---

### **2. SUGEST√ÉO INTELIGENTE DE ALTERNATIVAS T√âCNICAS** üü° PRIORIDADE M√âDIA

**Problema Atual:**
Cliente escolhe manualmente entre 6 alternativas (pode escolher errado)

**Com ML:**
```
IA analisa:
- Caracter√≠sticas do projeto (profundidade, dist√¢ncia, etc)
- PDIs similares aprovados pela ANP
- Hist√≥rico de sucesso de cada t√©cnica

Recomenda: "Para seu projeto, recomendamos:
1. Remo√ß√£o Completa (85% de confian√ßa)
   - 12 projetos similares aprovados
   - Custo m√©dio: USD 45M
   - Tempo m√©dio: 18 meses
2. Rigs-to-Reefs (60% de confian√ßa)
   - 5 projetos similares aprovados
   - Custo 40% menor, mas licenciamento +6 meses"
```

**Implementa√ß√£o:**

```python
from sklearn.neighbors import KNeighborsClassifier

# Dataset: projetos passados com t√©cnica aprovada
df_historico = pd.DataFrame({
    'lamina_agua': [1500, 2200, 800, ...],
    'distancia_costa': [120, 185, 45, ...],
    'num_pocos': [5, 8, 3, ...],
    'tecnica_aprovada': ['remocao_completa', 'rigs_to_reefs', ...]
})

# Treinar classificador
X = df_historico[['lamina_agua', 'distancia_costa', 'num_pocos']]
y = df_historico['tecnica_aprovada']

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X, y)

# Prever para novo projeto
novo = [[2100, 185, 8]]  # lamina, distancia, pocos
tecnica_recomendada = knn.predict(novo)
probabilidades = knn.predict_proba(novo)

# Resultado: "remocao_completa" (85% de confian√ßa)
```

**Benef√≠cio:**
- Cliente n√£o erra na escolha
- Taxa de aprova√ß√£o ANP aumenta
- Diferencial competitivo

---

### **3. DETEC√á√ÉO DE ANOMALIAS (Alertas Inteligentes)** üü° PRIORIDADE M√âDIA

**Problema Atual:**
Sistema aceita qualquer valor inserido (cliente pode errar)

**Com ML:**
```
IA detecta:
‚ùå "Custo de R$ 5M para 10 po√ßos em √°guas profundas √© MUITO BAIXO"
‚ùå "Cronograma de 3 meses para FPSO √© IRREALISTA"
‚ùå "Profundidade de 500m em Bacia de Santos √© AT√çPICA"

‚úÖ Alerta em tempo real
‚úÖ Sugere valores t√≠picos
‚úÖ Explica o porqu√™
```

**Implementa√ß√£o:**

```python
from sklearn.ensemble import IsolationForest

# Treinar com dados normais
df_normal = pd.DataFrame({
    'num_pocos': [3, 5, 8, 12, 6, ...],
    'custo_milhoes': [25, 42, 78, 105, 51, ...],
    'duracao_meses': [12, 18, 24, 30, 20, ...]
})

# Modelo de detec√ß√£o
iso_forest = IsolationForest(contamination=0.1)
iso_forest.fit(df_normal)

# Verificar novo input
novo_input = pd.DataFrame({
    'num_pocos': [10],
    'custo_milhoes': [5],  # MUITO BAIXO!
    'duracao_meses': [3]   # MUITO R√ÅPIDO!
})

anomalia = iso_forest.predict(novo_input)
# Resultado: -1 (anomalia detectada)

# Mostrar alerta no sistema
if anomalia == -1:
    alert("‚ö†Ô∏è Valores inseridos est√£o fora do padr√£o. Verifique!")
```

**Benef√≠cio:**
- Evita erros grosseiros
- Aumenta qualidade dos PDIs
- Cliente confia mais no sistema

---

### **4. PREVIS√ÉO DE TEMPO DE APROVA√á√ÉO ANP** üü¢ PRIORIDADE BAIXA

**Com ML:**
```
IA prev√™:
"Seu PDI tem 92% de chance de aprova√ß√£o na 1¬™ rodada"
"Tempo estimado de an√°lise ANP: 45-60 dias"

Baseado em:
- Completude do documento
- Hist√≥rico de aprova√ß√µes
- Similaridade com PDIs aprovados
```

**Implementa√ß√£o:**

```python
from sklearn.linear_model import LogisticRegression

# Dataset: PDIs submetidos + resultado
df_submetidos = pd.DataFrame({
    'completude_pct': [95, 78, 88, 100, ...],
    'num_revisoes': [1, 3, 2, 0, ...],
    'complexidade': [2, 4, 3, 2, ...],  # 1-5
    'aprovado_primeira': [1, 0, 1, 1, ...]  # 1=sim, 0=n√£o
})

# Treinar modelo
X = df_submetidos[['completude_pct', 'num_revisoes', 'complexidade']]
y = df_submetidos['aprovado_primeira']

lr = LogisticRegression()
lr.fit(X, y)

# Prever novo PDI
novo = [[98, 1, 3]]  # 98% completo, 1 revis√£o, complexidade 3
prob_aprovacao = lr.predict_proba(novo)[0][1]
# Resultado: 92% de chance de aprova√ß√£o
```

**Benef√≠cio:**
- Cliente sabe o que esperar
- Identifica pontos fracos antes de submeter
- Reduz ansiedade do cliente

---

### **5. OTIMIZA√á√ÉO DE CRONOGRAMA** üü¢ PRIORIDADE BAIXA

**Com ML:**
```
IA otimiza sequ√™ncia de atividades:
"Trocar ordem de X e Y economiza 2 meses"
"Weather window ideal: Mar√ßo-Outubro (evita atrasos)"
```

**Implementa√ß√£o:**

```python
import networkx as nx
from sklearn.linear_model import LinearRegression

# An√°lise de depend√™ncias e dura√ß√£o √≥tima
atividades = {
    'mobilizacao': {'duracao_media': 2, 'predecessores': []},
    'pa_pocos': {'duracao_media': 12, 'predecessores': ['mobilizacao']},
    'remocao_fpso': {'duracao_media': 6, 'predecessores': ['pa_pocos']}
}

# Modelo prev√™ dura√ß√£o real baseado em fatores externos
# (clima, disponibilidade de sonda, etc)
```

---

## üèóÔ∏è ARQUITETURA ML RECOMENDADA

### **Fase 1: Backend Python (Atual - Vi√°vel AGORA)**

```
Estrutura de Pastas:
NEPTUNO/
‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ custo_predictor.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tecnica_classifier.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ anomaly_detector.pkl
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îî‚îÄ‚îÄ dataset/
‚îÇ       ‚îú‚îÄ‚îÄ pdi_001.json
‚îÇ       ‚îú‚îÄ‚îÄ pdi_002.json
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ ml_api.py  (Flask/FastAPI)
‚îî‚îÄ‚îÄ (frontend atual)
```

**API Simples:**

```python
# ml/api/ml_api.py
from flask import Flask, request, jsonify
import pickle

app = Flask(__name__)

# Carregar modelo treinado
with open('models/custo_predictor.pkl', 'rb') as f:
    model_custo = pickle.load(f)

@app.route('/predict/custo', methods=['POST'])
def predict_custo():
    data = request.json
    features = [
        data['num_pocos'],
        data['profundidade_media'],
        data['lamina_agua'],
        data['distancia_costa']
    ]

    custo = model_custo.predict([features])[0]

    return jsonify({
        'custo_previsto_usd': float(custo),
        'margem_erro': 0.05  # ¬±5%
    })

if __name__ == '__main__':
    app.run(port=5000)
```

**Integra√ß√£o Frontend:**

```javascript
// No PDICalculos.js
const calcularCustosComML = async (pdiData) => {
  try {
    const response = await fetch('http://localhost:5000/predict/custo', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        num_pocos: pdiData.inventario.pocos.length,
        profundidade_media: calcularProfundidadeMedia(pdiData),
        lamina_agua: parseFloat(pdiData.referencia.profundidade),
        distancia_costa: parseFloat(pdiData.referencia.distanciaCosta)
      })
    });

    const resultado = await response.json();

    return {
      custo_ml: resultado.custo_previsto_usd,
      custo_parametrico: calcularCustoParametrico(pdiData),
      recomendacao: 'Usar m√©dia dos dois para maior precis√£o'
    };
  } catch (error) {
    // Fallback para c√°lculo param√©trico se API offline
    return calcularCustoParametrico(pdiData);
  }
};
```

---

### **Fase 2: TensorFlow.js (Futuro - Browser)**

**Vantagem:** Modelo roda no navegador (sem backend)

```javascript
// ml/model.js
import * as tf from '@tensorflow/tfjs';

// Carregar modelo treinado
const model = await tf.loadLayersModel('/models/custo_model.json');

// Prever
const input = tf.tensor2d([[8, 3500, 2100, 185]]);
const prediction = model.predict(input);
const custo = await prediction.data();
// Resultado: [178500000] (USD 178.5M)
```

**Benef√≠cios:**
- Sem necessidade de servidor backend
- Mais r√°pido (local)
- Funciona offline

---

## üìä DATASET - COMO COLETAR DADOS

### **Op√ß√£o 1: Dados P√∫blicos ANP**

```python
# Scraping de PDIs p√∫blicos (aprovados)
import requests
from bs4 import BeautifulSoup

url = 'https://www.gov.br/anp/pt-br/assuntos/exploracao-e-producao-de-oleo-e-gas/desativacao'
response = requests.get(url)
# Parse PDFs p√∫blicos e extrair dados
```

**Fontes:**
- PDIs aprovados publicados pela ANP
- Relat√≥rios de sustentabilidade de operadoras
- Dados abertos gov.br
- Papers acad√™micos

---

### **Op√ß√£o 2: Dados Sint√©ticos (Bootstrap)**

```python
# Gerar dados sint√©ticos para treinar modelo inicial
import numpy as np

def gerar_pdi_sintetico(n=1000):
    np.random.seed(42)

    data = {
        'num_pocos': np.random.randint(1, 20, n),
        'profundidade_media': np.random.randint(1000, 6000, n),
        'lamina_agua': np.random.randint(50, 3000, n),
        'distancia_costa': np.random.randint(10, 400, n)
    }

    # F√≥rmula base + ru√≠do aleat√≥rio
    data['custo_total'] = (
        data['num_pocos'] * 5_000_000 +
        data['profundidade_media'] * 10_000 +
        data['lamina_agua'] * 15_000 +
        np.random.normal(0, 5_000_000, n)  # ru√≠do
    )

    return pd.DataFrame(data)

df_treino = gerar_pdi_sintetico(1000)
```

---

### **Op√ß√£o 3: Dados Reais dos Clientes (Melhor)**

```
Cada PDI criado pelo NEPTUNO exporta JSON:
‚Üí Salvar em database
‚Üí Incrementar dataset
‚Üí Re-treinar modelo mensalmente

Ap√≥s 50 PDIs reais:
- Modelo supera benchmarks est√°ticos
- Precis√£o aumenta continuamente
- Sistema aprende padr√µes brasileiros espec√≠ficos
```

---

## üöÄ ROADMAP DE IMPLEMENTA√á√ÉO ML

### **Sprint 1 (1 semana): Coleta de Dados**
- [ ] Implementar logging de PDIs criados
- [ ] Exportar JSONs automaticamente
- [ ] Criar banco de dados (SQLite ou MongoDB)
- [ ] Coletar 20-50 PDIs (sint√©ticos + p√∫blicos)

### **Sprint 2 (1 semana): Treinar Modelo v1**
- [ ] Preparar dataset (limpeza, normaliza√ß√£o)
- [ ] Treinar modelo de previs√£o de custos
- [ ] Validar com cross-validation
- [ ] Salvar modelo (.pkl)

### **Sprint 3 (1 semana): API Backend**
- [ ] Criar API Flask/FastAPI
- [ ] Endpoint `/predict/custo`
- [ ] Deploy local (localhost:5000)
- [ ] Integrar com frontend

### **Sprint 4 (1 semana): Testes e Ajustes**
- [ ] Comparar ML vs benchmarks est√°ticos
- [ ] Ajustar hiperpar√¢metros
- [ ] Adicionar explicabilidade (SHAP)
- [ ] Documentar

### **Fase 2 (1-2 meses): Modelos Adicionais**
- [ ] Classificador de alternativas t√©cnicas
- [ ] Detector de anomalias
- [ ] Otimizador de cronograma

### **Fase 3 (3-6 meses): Migrar para TensorFlow.js**
- [ ] Converter modelos para TFJS
- [ ] Rodar 100% no navegador
- [ ] Eliminar backend Python

---

## üí∞ IMPACTO COMERCIAL DO ML

### **Diferencia√ß√£o de Mercado:**

**Sem ML (Atual):**
```
"Sistema automatizado com benchmarks da ind√∫stria"
```

**Com ML:**
```
"Sistema com INTELIG√äNCIA ARTIFICIAL que aprende
com cada PDI e fica mais preciso ao longo do tempo"
```

### **Precifica√ß√£o:**

Adicionar **20-30% ao pre√ßo** dos pacotes:

| Pacote | Atual | Com ML | Aumento |
|--------|-------|--------|---------|
| Bronze | R$ 18k | R$ 22k | +22% |
| Prata | R$ 45k | R$ 55k | +22% |
| Ouro | R$ 85k | R$ 105k | +24% |

**Justificativa:**
- Precis√£o 3x maior (¬±5% vs ¬±15%)
- Sugest√µes inteligentes
- Detec√ß√£o de erros
- Diferencial competitivo √∫nico

---

## üìö FERRAMENTAS E BIBLIOTECAS

### **Python (Backend):**
```bash
pip install numpy pandas scikit-learn tensorflow flask joblib
```

### **JavaScript (Frontend):**
```bash
npm install @tensorflow/tfjs
```

### **Visualiza√ß√£o:**
```bash
pip install matplotlib seaborn plotly
```

### **MLOps:**
```bash
pip install mlflow wandb  # tracking de experimentos
```

---

## üéØ CONCLUS√ÉO

### **ML no NEPTUNO √© VI√ÅVEL porque:**

‚úÖ **J√° exporta dados** (estrutura pronta)
‚úÖ **Problema bem definido** (regress√£o de custos)
‚úÖ **Valor claro** (precis√£o = $ economizado)
‚úÖ **Escal√°vel** (quanto mais PDIs, melhor)

### **Pr√≥ximo Passo Imediato:**

1. **Coletar 50 PDIs** (p√∫blicos + sint√©ticos)
2. **Treinar modelo b√°sico** (1 dia)
3. **Criar API Flask** (1 dia)
4. **Integrar no sistema** (0.5 dia)
5. **Testar e validar** (0.5 dia)

**Total:** 3-4 dias de trabalho
**Resultado:** NEPTUNO v3.0 com IA ü§ñ

---

**Quer que eu comece implementando a Fase 1 (Backend ML)?**
